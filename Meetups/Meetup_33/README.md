# 33rd Deep Learning Meetup in Vienna

* Date: 2020-02-26
* Venue: Magenta
* Meetup Page: https://www.meetup.com/Vienna-Deep-Learning-Meetup/events/268292554/

* Agenda, Announcements and Hot Topics:
[[Slides](<./slides/33rd Deep Learning Meetup Intro - Announcements - Hot Topics.pdf>)]

## Details

Dear Deep Learners,

Our February meetup will be on Wednesday, February 26th, at Magenta. We will have a main talk about speech synthesis, followed by an overview of current hardware options for deep learning.

**Talk 1:
And then they began to speak!**
Towards end-to-end speech synthesis, and back again?
by Markus Toman, neuratec and VocaliD
[[Slides](<./slides/speech_synthesis_mtoman_talk.pdf>)]

In recent years research progressed to the point where machines are, when certain conditions are met, able to mimic human speech with sufficient naturalness to fool human listeners. While this opens up novel possibilities for applications like digital assistants, robots or avatars, it also creates challenges in the realm of deep fakes and voice authentication fraud.
In this talk we will take a look at the inner workings of modern speech synthesis systems and how they evolved in recent years. Such systems traditionally encode linguistic and acoustic domain knowledge in the form of vast codebases, hand-crafted rules and statistical models. Recent advances in machine learning led to the gradual replacement of individual components of such systems with neural networks. We will look at the most important aspects of this shift towards end-to-end synthesis where almost the whole process of generating waveforms from text is performed by neural networks, inferring domain knowledge exclusively from data. The mechanics of prominent model architectures like WaveNet and Tacotron will be presentend and specific challenges of personalized speech synthesis, like speaker adaptation and multi-speaker models, will also be addressed. Lastly, we will question the feasibility of full end-to-end system with recent research partially incorporating traditional methods in their systems.

**Talk 2:
Deep Learning Hardware Overview: What and where to buy or rent**
by Jan Schlüter, René Donner and Thomas Lidy
[[Slides](<./slides/DL_Hardware_Overview.pdf>)]

For all but very small-scale experiments, deep learning research has become dependent on massively parallel computing devices such as GPUs. We will give an overview on what is currently available on the market, both in terms of GPUs and in terms of servers for housing them, and give concrete recommendations on what to pay attention to when deciding on a purchase. We will contrast this with renting options from well-known and less well-known cloud providers. Whether you are looking to get into deep learning or seriously extend your company or lab capacities, this will give you a head start in planning.

**Short Talk:
Tensorflow 2.1 optimization and deployment** by Franz Fürbass, AIT
[[Slides](<./slides/33rd Deep Learning Meetup Intro - Announcements - Hot Topics.pdf>)]

As usual, the meetup will be complemented by hot topics & latest news about Deep Learning, as well as networking.
We kindly thank Magenta for hosting our meetup and providing drinks & snacks.